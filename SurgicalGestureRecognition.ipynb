{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efc4f94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/boabangfrancis\n",
      "WARNING:tensorflow:From /Users/boabangfrancis/anaconda3/lib/python3.10/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.layers as layers\n",
    "from data_generator import DataGenerator\n",
    "import pandas as pd\n",
    "from __future__ import absolute_import, division, print_function\n",
    "import os\n",
    "import sys\n",
    "print(os.getcwd())\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= sys.argv[1]\n",
    "import tensorflow as tf\n",
    "#tf.compat.v1.enable_eager_execution()\n",
    "import numpy as np\n",
    "#from keras.datasets import cifar10\n",
    "import keras.callbacks as callbacks\n",
    "#import keras.utils.np_utils as kutils\n",
    "from tensorflow.keras import utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import plot_model\n",
    "#from wide_resnet import WRNModel\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "#from keras.utils import plot_model\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "from keras.utils import to_categorical\n",
    "import keras\n",
    "# parts of the code were adapted from https://github.com/jemiar/surgery-gesture-recog\n",
    "# parts of the code were adapted from https://github.com/yashkant/padam-tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "978467f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\F_BOABA'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a7e545",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3ad7f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "sys.path.append(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea9ea1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_directory = '/Users/boabangfrancis/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f136c0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile(\"/Users/boabangfrancis/Suturing.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"/Users/boabangfrancis/Suturing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa48495a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#h=[]\n",
    "#for i in os.listdir('/Users/boabangfrancis/transcription/transcription/'):\n",
    "#    if i.startswith('S'):\n",
    " #       h.append(i)\n",
    "#transcriptions=sorted(h[16:17])\n",
    "#transcriptions=['Suturing_B001.csv', 'Suturing_C001.csv','Suturing_D001.csv','Suturing_E001.csv', 'Suturing_F001.csv','Suturing_G001.csv','Suturing_H001.csv','Suturing_I001.csv']\n",
    "transcriptions=['Suturing_D001.csv', 'Suturing_D002.csv','Suturing_D003.csv','Suturing_D004.csv', 'Suturing_D005.csv','Suturing_E001.csv','Suturing_E002.csv','Suturing_E003.csv','Suturing_E004.csv','Suturing_E005.csv']\n",
    "#transcriptions=['Suturing_D001.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a32335e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_gesture(fromarray, height=240, width=320, folder='data_action\\\\', idnumber=1, base_directory=''):\n",
    "    data = []\n",
    "    labels = {}\n",
    "    video_directory = os.path.join(base_directory, 'Suturing', 'Suturing', 'video')\n",
    "\n",
    "    for arr in fromarray:\n",
    "        video_file = os.path.join(video_directory, arr[:-4] + '_capture1.avi')\n",
    "        cap = cv2.VideoCapture(video_file)\n",
    "        i = 1\n",
    "        red_frames = np.empty((0, height, width))\n",
    "        green_frames = np.empty((0, height, width))\n",
    "        blue_frames = np.empty((0, height, width))\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            if i % 3 == 1:\n",
    "                frame = cv2.resize(frame, (width, height), interpolation=cv2.INTER_AREA)\n",
    "                f = np.asarray(frame)\n",
    "                f = cv2.cvtColor(f, cv2.COLOR_BGR2RGB)\n",
    "                red_frames = np.append(red_frames, np.expand_dims(f[:,:,0], axis=0), axis=0)\n",
    "                green_frames = np.append(green_frames, np.expand_dims(f[:,:,1], axis=0), axis=0)\n",
    "                blue_frames = np.append(blue_frames, np.expand_dims(f[:,:,2], axis=0), axis=0)\n",
    "            i += 1\n",
    "        cap.release()\n",
    "\n",
    "        red_frames = red_frames / 255.0\n",
    "        green_frames = green_frames / 255.0\n",
    "        blue_frames = blue_frames / 255.0\n",
    "\n",
    "        df = pd.read_csv(os.path.join(base_directory + 'transcription' + arr[:-4] + '.csv')) \n",
    "        arr_gesture = np.array(df)\n",
    "\n",
    "        for t in arr_gesture[10:-4]:\n",
    "            left = (t[0] + 1) // 3\n",
    "            right = (t[1] - 1) // 3 + 1\n",
    "            w = t[2]\n",
    "            c = w[-1:]\n",
    "            num_blocks = (right - left + 1) // 10\n",
    "            for index in range(num_blocks):\n",
    "                block = np.concatenate([\n",
    "                    red_frames[left+index*10:left+(index+1)*10,:,:],\n",
    "                    green_frames[left+index*10:left+(index+1)*10,:,:],\n",
    "                    blue_frames[left+index*10:left+(index+1)*10,:,:]], axis=2)\n",
    "                npy_name = 'id_' + str(idnumber)\n",
    "                temp_obj = {'id': npy_name, 'file': arr, 'gesture': c}\n",
    "                data.append(npy_name)\n",
    "                labels[npy_name] = c\n",
    "                np.save(os.path.join(base_directory, folder, npy_name + '.npy'), block)\n",
    "                idnumber += 1\n",
    "\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea9002eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b41d2d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(height=240, width=320):\n",
    "    # shape of input: variable number frames x height x width x 3 channels (RGB)\n",
    "    input = tf.keras.Input((10, height, width, 3))\n",
    "\n",
    "    # 1st ConvLSTM block includes Conv2D with 8 filters, MaxPool2D and BatchNormalization\n",
    "    # Using keras TimeDistributed layer to apply Conv2D, MaxPool2D and BatchNormalization to each frame\n",
    "    conv2D_1 = layers.Conv2D(filters=8, kernel_size=(3,3), activation='relu')\n",
    "    x = layers.TimeDistributed(conv2D_1)(input)\n",
    "    maxpool_1 = layers.MaxPool2D(pool_size=(2,2))\n",
    "    x = layers.TimeDistributed(maxpool_1)(x)\n",
    "    batchnorm_1 = layers.BatchNormalization()\n",
    "    x = layers.TimeDistributed(batchnorm_1)(x)\n",
    "\n",
    "    # 2nd ConvLSTM block includes Conv2D with 16 filters, MaxPool2D and BatchNormalization\n",
    "    # Using keras TimeDistributed layer to apply Conv2D, MaxPool2D and BatchNormalization to each frame\n",
    "    conv2D_2 = layers.Conv2D(filters=16, kernel_size=(3,3), activation='relu')\n",
    "    x = layers.TimeDistributed(conv2D_2)(x)\n",
    "    maxpool_2 = layers.MaxPool2D(pool_size=(2,2))\n",
    "    x = layers.TimeDistributed(maxpool_2)(x)\n",
    "    batchnorm_2 = layers.BatchNormalization()\n",
    "    x = layers.TimeDistributed(batchnorm_2)(x)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # 3nd ConvLSTM block includes Conv2D with 32 filters, MaxPool2D and BatchNormalization\n",
    "    # Using keras TimeDistributed layer to apply Conv2D, MaxPool2D and BatchNormalization to each frame\n",
    "    conv2D_3 = layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu')\n",
    "    x = layers.TimeDistributed(conv2D_3)(x)\n",
    "    maxpool_3 = layers.MaxPool2D(pool_size=(2,2))\n",
    "    x = layers.TimeDistributed(maxpool_3)(x)\n",
    "    batchnorm_3 = layers.BatchNormalization()\n",
    "    x = layers.TimeDistributed(batchnorm_3)(x)\n",
    "    \n",
    "    \n",
    "        \n",
    "    # 4nd ConvLSTM block includes Conv2D with 16 filters, MaxPool2D and BatchNormalization\n",
    "    # Using keras TimeDistributed layer to apply Conv2D, MaxPool2D and BatchNormalization to each frame\n",
    "    conv2D_4 = layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu')\n",
    "    x = layers.TimeDistributed(conv2D_4)(x)\n",
    "    maxpool_4 = layers.MaxPool2D(pool_size=(2,2))\n",
    "    x = layers.TimeDistributed(maxpool_4)(x)\n",
    "    batchnorm_4 = layers.BatchNormalization()\n",
    "    x = layers.TimeDistributed(batchnorm_4)(x)\n",
    "    \n",
    "    \n",
    "    # 5nd ConvLSTM block includes Conv2D with 128 filters, MaxPool2D and BatchNormalization\n",
    "    # Using keras TimeDistributed layer to apply Conv2D, MaxPool2D and BatchNormalization to each frame\n",
    "    conv2D_5 = layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu')\n",
    "    x = layers.TimeDistributed(conv2D_5)(x)\n",
    "    maxpool_5 = layers.MaxPool2D(pool_size=(2,2))\n",
    "    x = layers.TimeDistributed(maxpool_5)(x)\n",
    "    batchnorm_5 = layers.BatchNormalization()\n",
    "    x = layers.TimeDistributed(batchnorm_5)(x)\n",
    "    \n",
    "    \n",
    "\n",
    "    # Flatten x to supply it to LSTM layer\n",
    "    flatten = layers.Flatten()\n",
    "    x = layers.TimeDistributed(flatten)(x)\n",
    "\n",
    "    # LSTM layer with 8 output units at the last LSTM block\n",
    "    x = layers.LSTM(8, return_sequences=False)(x)\n",
    "    # Fully-connected layer with 32 units and L2 regularization\n",
    "    x = layers.Dense(units=4, activation='relu', kernel_regularizer=keras.regularizers.L2(0.00001))(x)\n",
    "\n",
    "    # output shape (10,)\n",
    "    output = layers.Dense(units=10, activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.Model(input, output, name='ConvLSTM')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13483ac",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20aaca2e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Create data generator for training and validation\n",
    "\n",
    "data, labels =save_gesture(fromarray=transcriptions, height=240, width=320, folder='data_action/', idnumber=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "780621e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_params = {\n",
    "    \n",
    "    \n",
    "    'proposed_ASGD': {\n",
    "        'weight_decay': 0.0001,\n",
    "        'lr_min_d': 0.00001,\n",
    "        'lr_max_d':0.0001,\n",
    "        #'lr': 0, # dummy value\n",
    "        'b1': 0.9,\n",
    "        'b2': 0.999,\n",
    "        'color': 'red',\n",
    "        'linestyle':'-'\n",
    "    },\n",
    "    \n",
    "    \n",
    "    'proposed_ASGD_adam_version': {\n",
    "        'weight_decay': 0.00001,\n",
    "        'lr_min_d': 0.00001,\n",
    "        'lr_max_d':0.0001,\n",
    "        #'lr': 0, # dummy value\n",
    "        'b1': 0.9,\n",
    "        'b2': 0.999,\n",
    "        'color': 'red',\n",
    "        'linestyle':'-'\n",
    "    },\n",
    "    \n",
    "    'padam': {\n",
    "        'weight_decay': 0.0001,\n",
    "        'lr_max': 0.01,\n",
    "        'p': 0.125,\n",
    "        'b1': 0.9,\n",
    "        'b2': 0.999,\n",
    "        'color': 'darkred',\n",
    "        'linestyle':'-'\n",
    "    },\n",
    "    'adam': {\n",
    "        'weight_decay': 0.0001,\n",
    "        'lr_min': 0.00001,\n",
    "        'b1': 0.9,\n",
    "        'b2': 0.99,\n",
    "        'color': 'orange',\n",
    "        'linestyle':'--'\n",
    "    },\n",
    "    'adamw': {\n",
    "        'weight_decay': 0.025,\n",
    "        'lr_min': 0.00001,\n",
    "        'b1': 0.9,\n",
    "        'b2': 0.99,\n",
    "        'color': 'magenta',\n",
    "        'linestyle':'--'\n",
    "    },\n",
    "    'amsgrad': {\n",
    "        'weight_decay': 0.0001,\n",
    "        'lr_min': 0.00001,\n",
    "        'b1': 0.9,\n",
    "        'b2': 0.99,\n",
    "        'color' : 'darkgreen',\n",
    "        'linestyle':'-.'\n",
    "    },\n",
    "    'sgd': {\n",
    "        'weight_decay': 0.0005,\n",
    "        'lr_max': 0.001,\n",
    "        'm': 0.9,\n",
    "        'color': 'blue',\n",
    "        'linestyle':'-'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1658b148",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "#ham_messages=[{'id_1','id_1','id_1','id_1','id_3','id_1','id_3','id_2','id_1','id_1','id_4','id_1','id_1'}]\n",
    "ham_downsample = resample([labels],\n",
    "             replace=True,\n",
    "             n_samples=len([labels]),\n",
    "             random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e3c1232",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f4f7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(filepath, model):\n",
    "    file = h5py.File(filepath,'w')\n",
    "    weight = model.get_weights()\n",
    "    for i in range(len(weight)):\n",
    "        file.create_dataset('weight'+str(i),data=weight[i])\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7683747",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(filepath, model):\n",
    "    file=h5py.File(filepath,'r')\n",
    "    weight = []\n",
    "    for i in range(len(file.keys())):\n",
    "        weight.append(file['weight'+str(i)][:])\n",
    "    model.set_weights(weight)\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a510d859",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dimension=np.load('/Users/boabangfrancis/data_action/' + train)\n",
    "#dim_shape=(dimension.shape[0],dimension.shape[1], dimension.shape[2])\n",
    "#labelssorted=dict(sorted(labels.items()))\n",
    "params = {'dim': (10, 240, 320),\n",
    "          'batch_size': 1,\n",
    "          'n_classes': 10,\n",
    "          'n_channels': 3,\n",
    "          'folder': 'data_action/',\n",
    "          'shuffle': True}\n",
    "  \n",
    "#y = tf.keras.layers.UpSampling3D(size=10)(normals)   \n",
    "    \n",
    "train_generator = DataGenerator(data[21:], ham_downsample, **params)\n",
    "val_generator = DataGenerator(data[1:20], labels, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "5f3a7c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "#ham_messages=[{'id_1','id_1','id_1','id_1','id_3','id_1','id_3','id_2','id_1','id_1','id_4','id_1','id_1'}]\n",
    "ham_downsample_u= resample([ham_downsample],\n",
    "             replace=True,\n",
    "             n_samples=len([ham_downsample]),\n",
    "             random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4fb08bfb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ql/5nmrkn3145n9_pzr7h7w7_gh0000gn/T/ipykernel_1096/3508825634.py:49: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(generator=train_generator, validation_data=val_generator, epochs=200, shuffle=True, verbose=1, callbacks = [csv_logger])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 [==============================] - 13s 69ms/step - loss: 2.0700 - accuracy: 0.2686 - top_k_categorical_accuracy: 0.8114 - val_loss: 2.3666 - val_accuracy: 0.0526 - val_top_k_categorical_accuracy: 0.5263\n",
      "Epoch 2/200\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 1.6036 - accuracy: 0.4800 - top_k_categorical_accuracy: 0.9200 - val_loss: 1.9697 - val_accuracy: 0.2632 - val_top_k_categorical_accuracy: 0.7895\n",
      "Epoch 3/200\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 1.3794 - accuracy: 0.4629 - top_k_categorical_accuracy: 0.9829 - val_loss: 1.7334 - val_accuracy: 0.3158 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 1.2439 - accuracy: 0.5200 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.6124 - val_accuracy: 0.4211 - val_top_k_categorical_accuracy: 0.9474\n",
      "Epoch 5/200\n",
      "175/175 [==============================] - 12s 69ms/step - loss: 1.1122 - accuracy: 0.5714 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.8684 - val_accuracy: 0.3158 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "175/175 [==============================] - 12s 69ms/step - loss: 0.9186 - accuracy: 0.6629 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.8608 - val_accuracy: 0.3684 - val_top_k_categorical_accuracy: 0.8421\n",
      "Epoch 7/200\n",
      "175/175 [==============================] - 12s 69ms/step - loss: 1.4610 - accuracy: 0.4457 - top_k_categorical_accuracy: 0.9829 - val_loss: 1.8064 - val_accuracy: 0.3158 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 1.2202 - accuracy: 0.5143 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.4872 - val_accuracy: 0.1053 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 1.3772 - accuracy: 0.4114 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.6652 - val_accuracy: 0.3158 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 1.2210 - accuracy: 0.5086 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.9836 - val_accuracy: 0.2105 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 1.0653 - accuracy: 0.5600 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.6655 - val_accuracy: 0.3158 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 1.0641 - accuracy: 0.5200 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.0529 - val_accuracy: 0.3684 - val_top_k_categorical_accuracy: 0.9474\n",
      "Epoch 13/200\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 1.0324 - accuracy: 0.5714 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.0779 - val_accuracy: 0.2105 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 14/200\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 0.9029 - accuracy: 0.6514 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.8478 - val_accuracy: 0.2632 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 15/200\n",
      "175/175 [==============================] - 12s 69ms/step - loss: 0.9117 - accuracy: 0.5943 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.3611 - val_accuracy: 0.1579 - val_top_k_categorical_accuracy: 0.8947\n",
      "Epoch 16/200\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 0.9074 - accuracy: 0.6571 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.2853 - val_accuracy: 0.1579 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 17/200\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 0.8561 - accuracy: 0.6514 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.5593 - val_accuracy: 0.1053 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 18/200\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 0.8813 - accuracy: 0.6400 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.1228 - val_accuracy: 0.1053 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 19/200\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 0.9210 - accuracy: 0.6457 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.9846 - val_accuracy: 0.3158 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 20/200\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 0.8809 - accuracy: 0.6286 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.2013 - val_accuracy: 0.2632 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 21/200\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 0.7566 - accuracy: 0.7429 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.5827 - val_accuracy: 0.1053 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 22/200\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 0.6387 - accuracy: 0.7257 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.8837 - val_accuracy: 0.2632 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 23/200\n",
      "175/175 [==============================] - 12s 69ms/step - loss: 0.6216 - accuracy: 0.7886 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.8160 - val_accuracy: 0.2632 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 24/200\n",
      "175/175 [==============================] - 12s 69ms/step - loss: 0.6864 - accuracy: 0.7371 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.9417 - val_accuracy: 0.3158 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 25/200\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 0.6775 - accuracy: 0.7200 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.8446 - val_accuracy: 0.1579 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 26/200\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 0.8173 - accuracy: 0.6857 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.4297 - val_accuracy: 0.1579 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 27/200\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 0.7731 - accuracy: 0.7143 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.6792 - val_accuracy: 0.3158 - val_top_k_categorical_accuracy: 0.9474\n",
      "Epoch 28/200\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 0.6936 - accuracy: 0.7657 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.2697 - val_accuracy: 0.2105 - val_top_k_categorical_accuracy: 0.8947\n",
      "Epoch 29/200\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 0.6014 - accuracy: 0.7657 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.3434 - val_accuracy: 0.3158 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 30/200\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 0.5789 - accuracy: 0.8114 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.2573 - val_accuracy: 0.1579 - val_top_k_categorical_accuracy: 0.8947\n",
      "Epoch 31/200\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 0.6149 - accuracy: 0.7829 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.6701 - val_accuracy: 0.2632 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 32/200\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 0.4663 - accuracy: 0.8286 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.1854 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.9474\n",
      "Epoch 33/200\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 0.4982 - accuracy: 0.8229 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.7779 - val_accuracy: 0.2632 - val_top_k_categorical_accuracy: 0.8421\n",
      "Epoch 34/200\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 0.4364 - accuracy: 0.8514 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.2150 - val_accuracy: 0.2105 - val_top_k_categorical_accuracy: 0.9474\n",
      "Epoch 35/200\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 0.4574 - accuracy: 0.8457 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.0090 - val_accuracy: 0.2105 - val_top_k_categorical_accuracy: 0.8421\n",
      "Epoch 36/200\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 0.4605 - accuracy: 0.8400 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.5228 - val_accuracy: 0.1579 - val_top_k_categorical_accuracy: 0.7895\n",
      "Epoch 37/200\n",
      "175/175 [==============================] - 12s 69ms/step - loss: 0.5111 - accuracy: 0.8057 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.5108 - val_accuracy: 0.3684 - val_top_k_categorical_accuracy: 0.7368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/200\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 0.6196 - accuracy: 0.7829 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.6790 - val_accuracy: 0.3158 - val_top_k_categorical_accuracy: 0.8421\n",
      "Epoch 39/200\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 0.6398 - accuracy: 0.7771 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.8058 - val_accuracy: 0.3158 - val_top_k_categorical_accuracy: 0.9474\n",
      "Epoch 40/200\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 0.4447 - accuracy: 0.8457 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.7025 - val_accuracy: 0.3684 - val_top_k_categorical_accuracy: 0.7895\n",
      "Epoch 41/200\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 0.6001 - accuracy: 0.7886 - top_k_categorical_accuracy: 0.9943 - val_loss: 4.3152 - val_accuracy: 0.2632 - val_top_k_categorical_accuracy: 0.8947\n",
      "Epoch 42/200\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 0.5588 - accuracy: 0.8229 - top_k_categorical_accuracy: 0.9943 - val_loss: 4.8971 - val_accuracy: 0.3158 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 43/200\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 0.4804 - accuracy: 0.8000 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.3269 - val_accuracy: 0.3684 - val_top_k_categorical_accuracy: 0.8421\n",
      "Epoch 44/200\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 0.4255 - accuracy: 0.8571 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.5007 - val_accuracy: 0.2105 - val_top_k_categorical_accuracy: 0.8421\n",
      "Epoch 45/200\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 0.5142 - accuracy: 0.7943 - top_k_categorical_accuracy: 1.0000 - val_loss: 6.7342 - val_accuracy: 0.2105 - val_top_k_categorical_accuracy: 0.6842\n",
      "Epoch 46/200\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 0.6493 - accuracy: 0.7714 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.8154 - val_accuracy: 0.1579 - val_top_k_categorical_accuracy: 0.7368\n",
      "Epoch 47/200\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 0.6521 - accuracy: 0.8057 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.9621 - val_accuracy: 0.1053 - val_top_k_categorical_accuracy: 0.8421\n",
      "Epoch 48/200\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 0.4320 - accuracy: 0.8400 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.8421 - val_accuracy: 0.1579 - val_top_k_categorical_accuracy: 0.7895\n",
      "Epoch 49/200\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 0.4695 - accuracy: 0.8114 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.3311 - val_accuracy: 0.3158 - val_top_k_categorical_accuracy: 0.7895\n",
      "Epoch 50/200\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 0.4502 - accuracy: 0.8514 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.5637 - val_accuracy: 0.2105 - val_top_k_categorical_accuracy: 0.9474\n",
      "Epoch 51/200\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 0.3809 - accuracy: 0.8571 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.2758 - val_accuracy: 0.3158 - val_top_k_categorical_accuracy: 0.8421\n",
      "Epoch 52/200\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 0.3925 - accuracy: 0.8571 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.6210 - val_accuracy: 0.4211 - val_top_k_categorical_accuracy: 0.8421\n",
      "Epoch 53/200\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 0.4347 - accuracy: 0.8286 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.9715 - val_accuracy: 0.1053 - val_top_k_categorical_accuracy: 0.8947\n",
      "Epoch 54/200\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 0.3977 - accuracy: 0.8629 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.3579 - val_accuracy: 0.2632 - val_top_k_categorical_accuracy: 0.7895\n",
      "Epoch 55/200\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 0.4763 - accuracy: 0.8286 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.6732 - val_accuracy: 0.2632 - val_top_k_categorical_accuracy: 0.7368\n",
      "Epoch 56/200\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 0.3527 - accuracy: 0.8857 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.0707 - val_accuracy: 0.2632 - val_top_k_categorical_accuracy: 0.8947\n",
      "Epoch 57/200\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 0.3212 - accuracy: 0.8629 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.7303 - val_accuracy: 0.2105 - val_top_k_categorical_accuracy: 0.8421\n",
      "Epoch 58/200\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 0.3456 - accuracy: 0.8857 - top_k_categorical_accuracy: 1.0000 - val_loss: 7.0766 - val_accuracy: 0.0526 - val_top_k_categorical_accuracy: 0.7368\n",
      "Epoch 59/200\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 0.4127 - accuracy: 0.8457 - top_k_categorical_accuracy: 1.0000 - val_loss: 7.0586 - val_accuracy: 0.3158 - val_top_k_categorical_accuracy: 0.6842\n",
      "Epoch 60/200\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 0.3698 - accuracy: 0.8686 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.8460 - val_accuracy: 0.2632 - val_top_k_categorical_accuracy: 0.7368\n",
      "Epoch 61/200\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 0.3099 - accuracy: 0.8514 - top_k_categorical_accuracy: 1.0000 - val_loss: 6.1446 - val_accuracy: 0.2105 - val_top_k_categorical_accuracy: 0.8421\n",
      "Epoch 62/200\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 1.0202 - accuracy: 0.6571 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.5568 - val_accuracy: 0.0526 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 63/200\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 1.3877 - accuracy: 0.4171 - top_k_categorical_accuracy: 1.0000 - val_loss: 6.1011 - val_accuracy: 0.2632 - val_top_k_categorical_accuracy: 0.9474\n",
      "Epoch 64/200\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 1.3770 - accuracy: 0.5029 - top_k_categorical_accuracy: 0.9943 - val_loss: 4.0750 - val_accuracy: 0.3158 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 1.2476 - accuracy: 0.5543 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.2203 - val_accuracy: 0.2632 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 66/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 1.2503 - accuracy: 0.5200 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.0232 - val_accuracy: 0.1053 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 1.1756 - accuracy: 0.5371 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.9980 - val_accuracy: 0.0526 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 68/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 1.1863 - accuracy: 0.5314 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.4207 - val_accuracy: 0.3158 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 69/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 1.2017 - accuracy: 0.4857 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.8435 - val_accuracy: 0.2632 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 70/200\n",
      "175/175 [==============================] - 11s 65ms/step - loss: 1.1561 - accuracy: 0.5371 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.6272 - val_accuracy: 0.4211 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 1.0330 - accuracy: 0.5943 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.1754 - val_accuracy: 0.2105 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 1.1442 - accuracy: 0.5714 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.9985 - val_accuracy: 0.2105 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 73/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 1.0534 - accuracy: 0.5429 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.1862 - val_accuracy: 0.4211 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 1.1204 - accuracy: 0.5371 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.3886 - val_accuracy: 0.2105 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "175/175 [==============================] - 11s 65ms/step - loss: 1.1878 - accuracy: 0.5257 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.6914 - val_accuracy: 0.1579 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 76/200\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 1.1806 - accuracy: 0.5600 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.6890 - val_accuracy: 0.0526 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "175/175 [==============================] - 12s 70ms/step - loss: 0.9717 - accuracy: 0.6171 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.2241 - val_accuracy: 0.1053 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 1.0083 - accuracy: 0.6114 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.7345 - val_accuracy: 0.1053 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "175/175 [==============================] - 13s 71ms/step - loss: 1.0630 - accuracy: 0.5771 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.1687 - val_accuracy: 0.0526 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 1.0338 - accuracy: 0.5314 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.7443 - val_accuracy: 0.0526 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 1.1235 - accuracy: 0.5429 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.9988 - val_accuracy: 0.3158 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 0.9689 - accuracy: 0.5886 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.1786 - val_accuracy: 0.0526 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 1.0159 - accuracy: 0.6000 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.9368 - val_accuracy: 0.0526 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 84/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.9323 - accuracy: 0.6171 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.9762 - val_accuracy: 0.1053 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 0.8499 - accuracy: 0.6514 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.7993 - val_accuracy: 0.0526 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.8496 - accuracy: 0.6229 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.0921 - val_accuracy: 0.3684 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.8151 - accuracy: 0.6571 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.5225 - val_accuracy: 0.2105 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.9023 - accuracy: 0.5886 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.8398 - val_accuracy: 0.1579 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "175/175 [==============================] - 12s 70ms/step - loss: 1.0741 - accuracy: 0.6000 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.0567 - val_accuracy: 0.1053 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "175/175 [==============================] - 12s 70ms/step - loss: 0.8604 - accuracy: 0.6914 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.1678 - val_accuracy: 0.2632 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "175/175 [==============================] - 12s 71ms/step - loss: 1.0464 - accuracy: 0.5943 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.8904 - val_accuracy: 0.0526 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "175/175 [==============================] - 12s 71ms/step - loss: 0.9133 - accuracy: 0.6286 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.4213 - val_accuracy: 0.2632 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "175/175 [==============================] - 12s 71ms/step - loss: 0.8214 - accuracy: 0.6857 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.4667 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "175/175 [==============================] - 12s 70ms/step - loss: 0.7633 - accuracy: 0.7200 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.6545 - val_accuracy: 0.0526 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.8086 - accuracy: 0.6686 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.0031 - val_accuracy: 0.3158 - val_top_k_categorical_accuracy: 0.9474\n",
      "Epoch 96/200\n",
      "175/175 [==============================] - 11s 65ms/step - loss: 0.8239 - accuracy: 0.6800 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.4797 - val_accuracy: 0.2632 - val_top_k_categorical_accuracy: 0.7368\n",
      "Epoch 97/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.7974 - accuracy: 0.6857 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.4574 - val_accuracy: 0.3684 - val_top_k_categorical_accuracy: 0.8421\n",
      "Epoch 98/200\n",
      "175/175 [==============================] - 11s 66ms/step - loss: 0.7866 - accuracy: 0.7029 - top_k_categorical_accuracy: 1.0000 - val_loss: 6.6853 - val_accuracy: 0.1579 - val_top_k_categorical_accuracy: 0.7368\n",
      "Epoch 99/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.7110 - accuracy: 0.7371 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.6368 - val_accuracy: 0.3158 - val_top_k_categorical_accuracy: 0.8421\n",
      "Epoch 100/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.8186 - accuracy: 0.7029 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.6669 - val_accuracy: 0.2105 - val_top_k_categorical_accuracy: 0.9474\n",
      "Epoch 101/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.6953 - accuracy: 0.7486 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.1211 - val_accuracy: 0.1579 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.7532 - accuracy: 0.7086 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.9588 - val_accuracy: 0.1579 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.6629 - accuracy: 0.7429 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.8499 - val_accuracy: 0.1053 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.6439 - accuracy: 0.7714 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.9154 - val_accuracy: 0.1053 - val_top_k_categorical_accuracy: 0.9474\n",
      "Epoch 105/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.7283 - accuracy: 0.7486 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.4588 - val_accuracy: 0.1579 - val_top_k_categorical_accuracy: 0.9474\n",
      "Epoch 106/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.6456 - accuracy: 0.8000 - top_k_categorical_accuracy: 1.0000 - val_loss: 6.3590 - val_accuracy: 0.1579 - val_top_k_categorical_accuracy: 0.8947\n",
      "Epoch 107/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.8852 - accuracy: 0.7257 - top_k_categorical_accuracy: 1.0000 - val_loss: 6.9544 - val_accuracy: 0.2105 - val_top_k_categorical_accuracy: 0.6842\n",
      "Epoch 108/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.8248 - accuracy: 0.6743 - top_k_categorical_accuracy: 1.0000 - val_loss: 7.2326 - val_accuracy: 0.1053 - val_top_k_categorical_accuracy: 0.7895\n",
      "Epoch 109/200\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 0.7542 - accuracy: 0.7143 - top_k_categorical_accuracy: 1.0000 - val_loss: 6.1751 - val_accuracy: 0.3158 - val_top_k_categorical_accuracy: 0.6842\n",
      "Epoch 110/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 [==============================] - 12s 67ms/step - loss: 0.7720 - accuracy: 0.6914 - top_k_categorical_accuracy: 1.0000 - val_loss: 6.6068 - val_accuracy: 0.3158 - val_top_k_categorical_accuracy: 0.7895\n",
      "Epoch 111/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.6868 - accuracy: 0.7543 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.3284 - val_accuracy: 0.2632 - val_top_k_categorical_accuracy: 0.8947\n",
      "Epoch 112/200\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 0.6036 - accuracy: 0.7829 - top_k_categorical_accuracy: 1.0000 - val_loss: 8.2775 - val_accuracy: 0.2105 - val_top_k_categorical_accuracy: 0.7895\n",
      "Epoch 113/200\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 0.6941 - accuracy: 0.7543 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.1844 - val_accuracy: 0.1579 - val_top_k_categorical_accuracy: 0.9474\n",
      "Epoch 114/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.7029 - accuracy: 0.7371 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.2196 - val_accuracy: 0.2105 - val_top_k_categorical_accuracy: 0.9474\n",
      "Epoch 115/200\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 0.7122 - accuracy: 0.7257 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.6857 - val_accuracy: 0.1053 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 0.6663 - accuracy: 0.7886 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.9112 - val_accuracy: 0.0526 - val_top_k_categorical_accuracy: 0.8947\n",
      "Epoch 117/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.6850 - accuracy: 0.7600 - top_k_categorical_accuracy: 1.0000 - val_loss: 8.0020 - val_accuracy: 0.1579 - val_top_k_categorical_accuracy: 0.7368\n",
      "Epoch 118/200\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 0.6247 - accuracy: 0.7886 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.3619 - val_accuracy: 0.1053 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.7765 - accuracy: 0.7143 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.6930 - val_accuracy: 0.0526 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.6380 - accuracy: 0.7486 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.3680 - val_accuracy: 0.1053 - val_top_k_categorical_accuracy: 0.8947\n",
      "Epoch 121/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.5842 - accuracy: 0.7771 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.7575 - val_accuracy: 0.1579 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.6636 - accuracy: 0.7543 - top_k_categorical_accuracy: 1.0000 - val_loss: 6.0650 - val_accuracy: 0.2105 - val_top_k_categorical_accuracy: 0.8947\n",
      "Epoch 123/200\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 0.7018 - accuracy: 0.7257 - top_k_categorical_accuracy: 1.0000 - val_loss: 6.0793 - val_accuracy: 0.3684 - val_top_k_categorical_accuracy: 0.8947\n",
      "Epoch 124/200\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 0.6461 - accuracy: 0.7829 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.3687 - val_accuracy: 0.3684 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.5789 - accuracy: 0.8057 - top_k_categorical_accuracy: 1.0000 - val_loss: 6.4858 - val_accuracy: 0.2632 - val_top_k_categorical_accuracy: 0.8421\n",
      "Epoch 126/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.6950 - accuracy: 0.7486 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.6229 - val_accuracy: 0.2632 - val_top_k_categorical_accuracy: 0.8421\n",
      "Epoch 127/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.5992 - accuracy: 0.8000 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.3501 - val_accuracy: 0.2105 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.7240 - accuracy: 0.7086 - top_k_categorical_accuracy: 1.0000 - val_loss: 8.1945 - val_accuracy: 0.1053 - val_top_k_categorical_accuracy: 0.7895\n",
      "Epoch 129/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.6566 - accuracy: 0.7486 - top_k_categorical_accuracy: 1.0000 - val_loss: 8.2585 - val_accuracy: 0.2105 - val_top_k_categorical_accuracy: 0.6842\n",
      "Epoch 130/200\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 0.6471 - accuracy: 0.7600 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.6415 - val_accuracy: 0.2632 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.6656 - accuracy: 0.7657 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.6330 - val_accuracy: 0.1053 - val_top_k_categorical_accuracy: 0.9474\n",
      "Epoch 132/200\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 0.5419 - accuracy: 0.8171 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.4416 - val_accuracy: 0.1053 - val_top_k_categorical_accuracy: 0.9474\n",
      "Epoch 133/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.5355 - accuracy: 0.7943 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.0352 - val_accuracy: 0.2105 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.5298 - accuracy: 0.8000 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.4118 - val_accuracy: 0.1053 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 0.6717 - accuracy: 0.7543 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.3776 - val_accuracy: 0.0526 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 0.6611 - accuracy: 0.7543 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.9238 - val_accuracy: 0.1053 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 0.6003 - accuracy: 0.7771 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.2964 - val_accuracy: 0.2105 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.5846 - accuracy: 0.7771 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.8051 - val_accuracy: 0.0526 - val_top_k_categorical_accuracy: 0.8947\n",
      "Epoch 139/200\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 0.5967 - accuracy: 0.7771 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.2797 - val_accuracy: 0.1053 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 0.5989 - accuracy: 0.7829 - top_k_categorical_accuracy: 1.0000 - val_loss: 6.7728 - val_accuracy: 0.3158 - val_top_k_categorical_accuracy: 0.7368\n",
      "Epoch 141/200\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 0.5940 - accuracy: 0.7486 - top_k_categorical_accuracy: 1.0000 - val_loss: 7.7779 - val_accuracy: 0.1053 - val_top_k_categorical_accuracy: 0.8421\n",
      "Epoch 142/200\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 0.4912 - accuracy: 0.8171 - top_k_categorical_accuracy: 1.0000 - val_loss: 6.4310 - val_accuracy: 0.1053 - val_top_k_categorical_accuracy: 0.8947\n",
      "Epoch 143/200\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 0.5272 - accuracy: 0.8057 - top_k_categorical_accuracy: 1.0000 - val_loss: 9.1468 - val_accuracy: 0.1579 - val_top_k_categorical_accuracy: 0.7895\n",
      "Epoch 144/200\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 0.4661 - accuracy: 0.8343 - top_k_categorical_accuracy: 1.0000 - val_loss: 7.4167 - val_accuracy: 0.2105 - val_top_k_categorical_accuracy: 0.8421\n",
      "Epoch 145/200\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 0.4829 - accuracy: 0.8343 - top_k_categorical_accuracy: 1.0000 - val_loss: 7.8278 - val_accuracy: 0.2105 - val_top_k_categorical_accuracy: 0.8421\n",
      "Epoch 146/200\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 0.4965 - accuracy: 0.8229 - top_k_categorical_accuracy: 1.0000 - val_loss: 6.3556 - val_accuracy: 0.3158 - val_top_k_categorical_accuracy: 0.8947\n",
      "Epoch 147/200\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 0.3998 - accuracy: 0.8686 - top_k_categorical_accuracy: 1.0000 - val_loss: 7.2765 - val_accuracy: 0.1579 - val_top_k_categorical_accuracy: 0.8947\n",
      "Epoch 148/200\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 0.4041 - accuracy: 0.8743 - top_k_categorical_accuracy: 1.0000 - val_loss: 7.0184 - val_accuracy: 0.2105 - val_top_k_categorical_accuracy: 0.8421\n",
      "Epoch 149/200\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 0.4064 - accuracy: 0.8686 - top_k_categorical_accuracy: 1.0000 - val_loss: 7.8757 - val_accuracy: 0.2105 - val_top_k_categorical_accuracy: 0.7368\n",
      "Epoch 150/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.4832 - accuracy: 0.8229 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.9389 - val_accuracy: 0.2632 - val_top_k_categorical_accuracy: 0.9474\n",
      "Epoch 151/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.6436 - accuracy: 0.7600 - top_k_categorical_accuracy: 1.0000 - val_loss: 7.0942 - val_accuracy: 0.3158 - val_top_k_categorical_accuracy: 0.7368\n",
      "Epoch 152/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.7069 - accuracy: 0.7486 - top_k_categorical_accuracy: 1.0000 - val_loss: 6.3603 - val_accuracy: 0.3158 - val_top_k_categorical_accuracy: 0.8421\n",
      "Epoch 153/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.5719 - accuracy: 0.7600 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.3033 - val_accuracy: 0.2105 - val_top_k_categorical_accuracy: 0.8421\n",
      "Epoch 154/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.5740 - accuracy: 0.8114 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.6913 - val_accuracy: 0.2632 - val_top_k_categorical_accuracy: 0.8421\n",
      "Epoch 155/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.5753 - accuracy: 0.7943 - top_k_categorical_accuracy: 1.0000 - val_loss: 7.8956 - val_accuracy: 0.2105 - val_top_k_categorical_accuracy: 0.7895\n",
      "Epoch 156/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.6036 - accuracy: 0.7829 - top_k_categorical_accuracy: 1.0000 - val_loss: 7.4717 - val_accuracy: 0.3158 - val_top_k_categorical_accuracy: 0.7368\n",
      "Epoch 157/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.5000 - accuracy: 0.8171 - top_k_categorical_accuracy: 1.0000 - val_loss: 7.7330 - val_accuracy: 0.2632 - val_top_k_categorical_accuracy: 0.7368\n",
      "Epoch 158/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.5593 - accuracy: 0.7886 - top_k_categorical_accuracy: 1.0000 - val_loss: 6.7195 - val_accuracy: 0.2105 - val_top_k_categorical_accuracy: 0.6842\n",
      "Epoch 159/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.5343 - accuracy: 0.7886 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.4956 - val_accuracy: 0.1053 - val_top_k_categorical_accuracy: 0.8947\n",
      "Epoch 160/200\n",
      "175/175 [==============================] - 11s 65ms/step - loss: 0.5511 - accuracy: 0.7829 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.9163 - val_accuracy: 0.3158 - val_top_k_categorical_accuracy: 0.9474\n",
      "Epoch 161/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.5595 - accuracy: 0.7943 - top_k_categorical_accuracy: 1.0000 - val_loss: 7.3520 - val_accuracy: 0.2105 - val_top_k_categorical_accuracy: 0.7368\n",
      "Epoch 162/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.4914 - accuracy: 0.8114 - top_k_categorical_accuracy: 1.0000 - val_loss: 6.8483 - val_accuracy: 0.1579 - val_top_k_categorical_accuracy: 0.7895\n",
      "Epoch 163/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.4102 - accuracy: 0.8457 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.7035 - val_accuracy: 0.2105 - val_top_k_categorical_accuracy: 0.9474\n",
      "Epoch 164/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.5361 - accuracy: 0.7943 - top_k_categorical_accuracy: 1.0000 - val_loss: 8.7515 - val_accuracy: 0.0526 - val_top_k_categorical_accuracy: 0.7895\n",
      "Epoch 165/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.6940 - accuracy: 0.7657 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.1107 - val_accuracy: 0.0526 - val_top_k_categorical_accuracy: 0.9474\n",
      "Epoch 166/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.8702 - accuracy: 0.6743 - top_k_categorical_accuracy: 1.0000 - val_loss: 7.0762 - val_accuracy: 0.3158 - val_top_k_categorical_accuracy: 0.8421\n",
      "Epoch 167/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.7589 - accuracy: 0.7029 - top_k_categorical_accuracy: 1.0000 - val_loss: 8.9916 - val_accuracy: 0.2105 - val_top_k_categorical_accuracy: 0.7368\n",
      "Epoch 168/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.7115 - accuracy: 0.7314 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.8520 - val_accuracy: 0.2632 - val_top_k_categorical_accuracy: 0.9474\n",
      "Epoch 169/200\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 0.6061 - accuracy: 0.7886 - top_k_categorical_accuracy: 1.0000 - val_loss: 6.5813 - val_accuracy: 0.0526 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 0.6657 - accuracy: 0.7886 - top_k_categorical_accuracy: 1.0000 - val_loss: 6.6905 - val_accuracy: 0.3158 - val_top_k_categorical_accuracy: 0.8421\n",
      "Epoch 171/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.6465 - accuracy: 0.7886 - top_k_categorical_accuracy: 1.0000 - val_loss: 8.8946 - val_accuracy: 0.1053 - val_top_k_categorical_accuracy: 0.8421\n",
      "Epoch 172/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.6096 - accuracy: 0.8057 - top_k_categorical_accuracy: 1.0000 - val_loss: 7.4389 - val_accuracy: 0.0526 - val_top_k_categorical_accuracy: 0.9474\n",
      "Epoch 173/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.7263 - accuracy: 0.7314 - top_k_categorical_accuracy: 1.0000 - val_loss: 6.8743 - val_accuracy: 0.0526 - val_top_k_categorical_accuracy: 0.9474\n",
      "Epoch 174/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.5961 - accuracy: 0.7829 - top_k_categorical_accuracy: 1.0000 - val_loss: 6.2333 - val_accuracy: 0.1579 - val_top_k_categorical_accuracy: 0.8421\n",
      "Epoch 175/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.5310 - accuracy: 0.8057 - top_k_categorical_accuracy: 1.0000 - val_loss: 8.5414 - val_accuracy: 0.1053 - val_top_k_categorical_accuracy: 0.8421\n",
      "Epoch 176/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.6535 - accuracy: 0.7714 - top_k_categorical_accuracy: 1.0000 - val_loss: 7.6533 - val_accuracy: 0.2105 - val_top_k_categorical_accuracy: 0.8947\n",
      "Epoch 177/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.4731 - accuracy: 0.8286 - top_k_categorical_accuracy: 1.0000 - val_loss: 6.7991 - val_accuracy: 0.1579 - val_top_k_categorical_accuracy: 0.8421\n",
      "Epoch 178/200\n",
      "175/175 [==============================] - 11s 65ms/step - loss: 0.4419 - accuracy: 0.8514 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.7343 - val_accuracy: 0.1579 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.5209 - accuracy: 0.8114 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.1546 - val_accuracy: 0.2105 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.4803 - accuracy: 0.8286 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.1206 - val_accuracy: 0.0526 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.5025 - accuracy: 0.8114 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.6770 - val_accuracy: 0.2105 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 182/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 [==============================] - 12s 66ms/step - loss: 0.6244 - accuracy: 0.7943 - top_k_categorical_accuracy: 1.0000 - val_loss: 6.2153 - val_accuracy: 0.2105 - val_top_k_categorical_accuracy: 0.8947\n",
      "Epoch 183/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.4882 - accuracy: 0.8171 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.0709 - val_accuracy: 0.3158 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.5220 - accuracy: 0.8286 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.0570 - val_accuracy: 0.3158 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "175/175 [==============================] - 11s 65ms/step - loss: 0.4567 - accuracy: 0.8514 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.5881 - val_accuracy: 0.4211 - val_top_k_categorical_accuracy: 0.8947\n",
      "Epoch 186/200\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 0.3877 - accuracy: 0.8914 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.7643 - val_accuracy: 0.4737 - val_top_k_categorical_accuracy: 0.8947\n",
      "Epoch 187/200\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 0.4546 - accuracy: 0.8514 - top_k_categorical_accuracy: 1.0000 - val_loss: 6.5266 - val_accuracy: 0.1579 - val_top_k_categorical_accuracy: 0.9474\n",
      "Epoch 188/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.4158 - accuracy: 0.8686 - top_k_categorical_accuracy: 1.0000 - val_loss: 6.0256 - val_accuracy: 0.2632 - val_top_k_categorical_accuracy: 0.8421\n",
      "Epoch 189/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.6159 - accuracy: 0.7714 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.7745 - val_accuracy: 0.1053 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.6484 - accuracy: 0.7600 - top_k_categorical_accuracy: 1.0000 - val_loss: 6.2048 - val_accuracy: 0.2105 - val_top_k_categorical_accuracy: 0.7895\n",
      "Epoch 191/200\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 0.5320 - accuracy: 0.7886 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.5637 - val_accuracy: 0.2105 - val_top_k_categorical_accuracy: 0.9474\n",
      "Epoch 192/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.4057 - accuracy: 0.8743 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.9951 - val_accuracy: 0.2105 - val_top_k_categorical_accuracy: 0.8421\n",
      "Epoch 193/200\n",
      "175/175 [==============================] - 11s 65ms/step - loss: 0.5196 - accuracy: 0.8229 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.6099 - val_accuracy: 0.2105 - val_top_k_categorical_accuracy: 0.8947\n",
      "Epoch 194/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.4113 - accuracy: 0.8514 - top_k_categorical_accuracy: 1.0000 - val_loss: 6.3303 - val_accuracy: 0.2632 - val_top_k_categorical_accuracy: 0.8947\n",
      "Epoch 195/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.4218 - accuracy: 0.8457 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.8443 - val_accuracy: 0.3684 - val_top_k_categorical_accuracy: 0.6842\n",
      "Epoch 196/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.4972 - accuracy: 0.8743 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.1497 - val_accuracy: 0.3158 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 0.6075 - accuracy: 0.7829 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.8482 - val_accuracy: 0.2632 - val_top_k_categorical_accuracy: 0.8421\n",
      "Epoch 198/200\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 0.4696 - accuracy: 0.8229 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.4975 - val_accuracy: 0.2105 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.3952 - accuracy: 0.8571 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.5578 - val_accuracy: 0.3158 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 0.4330 - accuracy: 0.8343 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.1362 - val_accuracy: 0.3158 - val_top_k_categorical_accuracy: 1.0000\n",
      " 9/19 [=============>................] - ETA: 0s - loss: 5.6066 - accuracy: 0.3333 - top_k_categorical_accuracy: 1.0000    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ql/5nmrkn3145n9_pzr7h7w7_gh0000gn/T/ipykernel_1096/3508825634.py:50: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  scores = model.evaluate_generator(val_generator, verbose=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 16ms/step - loss: 5.0054 - accuracy: 0.2632 - top_k_categorical_accuracy: 1.0000\n",
      "Final test loss and accuracy: [5.0054030418396, 0.2631579041481018, 1.0]\n"
     ]
    }
   ],
   "source": [
    "from padam import Padam\n",
    "from amsgrad import AMSGrad\n",
    "from proposed_ASGD import Proposed_ASGD\n",
    "from proposed_ASGD_adam_version import  Proposed_ASGD_adam_version\n",
    "#learning_rate=0.00001\n",
    "#learning_rate_min=0.00001\n",
    "#learning_rate_max=0.001\n",
    "#optim_array=[ 'padam', 'proposed_ASGD_adam_version', 'proposed_ASGD',  'adam', 'amsgrad']\n",
    "#optim_array=[]\n",
    "optim_array=['padam']\n",
    "#optim_array=['padam']\n",
    "history={}\n",
    "for optimizer in optim_array:\n",
    "    op=optim_params[optimizer]\n",
    "    \n",
    "    logfile= 'log_' + optimizer +'_ExpectGoodResult' + '.csv'\n",
    "    #op['lr']=op['lr']\n",
    "   # learning_rate_min=op['lr_min']\n",
    "    \n",
    "    if optimizer == 'proposed_ASGD':\n",
    "        learning_rate_max=op['lr_max_d']/1\n",
    "        learning_rate_min=op['lr_min_d']/1\n",
    "        optim = Proposed_ASGD(learning_rate_min=learning_rate_min,learning_rate_max=learning_rate_max, beta1=op['b1'], beta2=op['b2'])\n",
    "    elif optimizer == 'proposed_ASGD_adam_version':\n",
    "        learning_rate_max=op['lr_max_d']/1\n",
    "        learning_rate_min=op['lr_min_d']/1\n",
    "        optim = Proposed_ASGD_adam_version(learning_rate_min=learning_rate_min,learning_rate_max=learning_rate_max, beta1=op['b1'], beta2=op['b2'])\n",
    "            \n",
    "    elif optimizer == 'padam':\n",
    "        learning_rate_max=op['lr_max']/1\n",
    "        optim = Padam(learning_rate=learning_rate_max, p=op['p'], beta1=op['b1'], beta2=op['b2'])\n",
    "    elif optimizer == 'adam':\n",
    "        learning_rate_min=op['lr_min']/1\n",
    "        optim = tf.train.AdamOptimizer(learning_rate=learning_rate_min, beta1=op['b1'], beta2=op['b2'])\n",
    "    elif optimizer == 'adamw':\n",
    "        learning_rate_min=op['lr_min']/1\n",
    "            # adamw = tf.contrib.opt.extend_with_decoupled_weight_decay(tf.train.AdamOptimizer)\n",
    "        optim = tf.contrib.opt.AdamWOptimizer(weight_decay=op['weight_decay'], learning_rate=learning_rate_min,  beta1=op['b1'], beta2=op['b2'])\n",
    "    elif optimizer == 'amsgrad':\n",
    "        learning_rate_min=op['lr_min']/1\n",
    "        optim = AMSGrad(learning_rate=learning_rate_min, beta1=op['b1'], beta2=op['b2'])\n",
    "    elif optimizer == 'sgd':\n",
    "        learning_rate_max=op['lr_max']/1\n",
    "        optim = tf.train.MomentumOptimizer(learning_rate=learning_rate_max, momentum=op['m'])\n",
    "    model = create_model(240, 320)  \n",
    "    model.compile(optimizer=optim, loss='categorical_crossentropy', metrics=['accuracy', 'top_k_categorical_accuracy'])\n",
    "    csv_logger = CSVLogger(logfile, append=True, separator=';')\n",
    "        #model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(), optimizer=keras.optimizers.SGD(learning_rate=learning_rate), metrics=metrics)\n",
    "    model.fit_generator(generator=train_generator, validation_data=val_generator, epochs=200, shuffle=True, verbose=1, callbacks = [csv_logger])\n",
    "    scores = model.evaluate_generator(val_generator, verbose=1)\n",
    "    print(\"Final test loss and accuracy:\", scores)\n",
    "    #save_model(save_model_filepath, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a698d11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272f2f41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffa28a6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b210fd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacc3b62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
